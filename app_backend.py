from flask import Flask, send_file, request, jsonify, session, render_template
import os
import uuid
import subprocess
from datetime import datetime
from langchain_google_genai import ChatGoogleGenerativeAI
from langchain_core.messages import HumanMessage, SystemMessage, AIMessage
from langchain_core.tools import tool
from typing import Optional
from dotenv import load_dotenv




# environment variables
load_dotenv()





app = Flask(__name__)
app.secret_key = os.urandom(24)  

conversation_messages = {}  
conversation_metadata = {}  

# Initialize LangChain Groq client
llm = None
llm_with_tools = None

# LATEX TOOLS AND COMPILATION FUNCTIONS




@tool
def write_latex(latex_code: str) -> dict:

    """
    Writes LaTeX code to an output.tex file.
    
    Args:
        latex_code (str): The LaTeX code to write to the file.
    
    Returns:
        dict: A dictionary containing:
            - success (bool): True if the write operation succeeded, False otherwise.
            - message (str): Status message or error details.
            - output_file (str, optional): Path to the written file if successful.
    """
    

    # DEBUG: Print when tool is being used
    print("\n" + "="*80)
    print("üîß WRITE_LATEX TOOL INVOKED")
    print("="*80)
    print(f"üìÑ LaTeX code length: {len(latex_code)} characters")
    print(f"‚è∞ Timestamp: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print("-"*80)
    print("üìù LATEX CODE CONTENT:")
    print("-"*80)
    print(latex_code)
    print("-"*80)
    
    try:
        tex_file = "output.tex"
        
        with open(tex_file, "w", encoding="utf-8") as f:
            f.write(latex_code)
        
        if os.path.exists(tex_file):
            print("‚úÖ SUCCESS: LaTeX code written to output.tex successfully")
            print("="*80 + "\n")
            return {
                "success": True,
                "message": "LaTeX code written to output.tex successfully.",
                "output_file": os.path.abspath(tex_file)
            }
        else:
            print("‚ùå FAILED: Could not verify that output.tex was written")
            print("="*80 + "\n")
            return {
                "success": False,
                "message": "Failed to verify that output.tex was written."
            }



    except PermissionError:
        print("‚ùå PERMISSION ERROR: Permission denied while writing to output.tex")
        print("="*80 + "\n")
        return {
            "success": False,
            "message": "Permission denied while writing to output.tex."
        }
    except Exception as e:
        print(f"‚ùå EXCEPTION ERROR: {str(e)}")
        print("="*80 + "\n")
        return {
            "success": False,
            "message": f"An unexpected error occurred: {str(e)}"
        }




def initialize_llm():
    global llm, llm_with_tools
    try:
        api_key = os.getenv('GOOGLE_API_KEY')
        if api_key:
            llm = ChatGoogleGenerativeAI(
                model="gemini-2.0-flash-001",
                temperature=0.7,
                max_tokens=2000,  # Increased for tool calls + LaTeX generation
                timeout=30,
                max_retries=2,
                google_api_key=api_key
            )
            print("‚úÖ LangChain Google Gemini client initialized successfully!")
            print(f"ü§ñ Using model: gemini-2.0-flash-001")
            
            # Bind tools to the LLM with proper configuration for Gemini
            llm_with_tools = llm.bind_tools([write_latex])
            print("üîß LaTeX writing tool bound to LLM")
        else:
            print("‚ö†Ô∏è  GOOGLE_API_KEY not found in environment variables")
            print("üí° Please create a .env file with your GOOGLE_API_KEY")
            print("üîó Get your API key from: https://aistudio.google.com/app/apikey")
    except Exception as e:
        print(f"‚ùå Error initializing LangChain Google Gemini client: {e}")

initialize_llm()

# LATEX COMPILATION FUNCTIONS



def clean_latex_code(raw_latex: str) -> str:
    """Clean up LaTeX code generated by LLM to ensure it compiles properly"""
    
    # Remove any explanatory text before \documentclass
    lines = raw_latex.split('\n')
    latex_start_idx = -1
    
    for i, line in enumerate(lines):
        if line.strip().startswith('\\documentclass'):
            latex_start_idx = i
            break
    
    if latex_start_idx == -1:
        print("‚ùå No \\documentclass found in generated LaTeX!")
        return raw_latex
    
    latex_lines = lines[latex_start_idx:]
    
    cleaned_latex = '\n'.join(latex_lines)
    
    if '\\end{document}' in cleaned_latex:
        end_doc_pos = cleaned_latex.find('\\end{document}') + len('\\end{document}')
        cleaned_latex = cleaned_latex[:end_doc_pos]
    
    replacements = {
        '[LINKEDIN_URL]': 'https://linkedin.com/in/yourprofile',
        '[LINKEDIN_DISPLAY]': 'yourprofile',
        '[GITHUB_URL]': 'https://github.com/yourprofile',
        '[GITHUB_DISPLAY]': 'yourprofile',
        '[USER_LINKEDIN_URL]': 'https://linkedin.com/in/yourprofile',
        '[USER_LINKEDIN_DISPLAY]': 'yourprofile',
        '[USER_GITHUB_URL]': 'https://github.com/yourprofile',
        '[USER_GITHUB_DISPLAY]': 'yourprofile',
    }
    
    for placeholder, replacement in replacements.items():
        cleaned_latex = cleaned_latex.replace(placeholder, replacement)
    




    import re


    cleaned_latex = re.sub(r'\\resumeItem\{\s*\}', '', cleaned_latex)
    cleaned_latex = re.sub(r'\\resumeItem\{\s+\}', '', cleaned_latex)
    
    cleaned_latex = re.sub(
        r'(\\resumeSubheading\s*\{[^}]+\}\s*\{[^}]+\}\s*\{[^}]+\}\s*\{[^}]+\})\s*\{[^}]*\}',
        r'\1',
        cleaned_latex
    )
    
    print(f"üßπ LaTeX cleaning completed:")
    print(f"   - Removed explanatory text")
    print(f"   - Fixed placeholder URLs")
    print(f"   - Cleaned empty resume items")
    print(f"   - Fixed malformed sections")
    
    return cleaned_latex




def compile_latex(latex_code: str) -> dict:
    """Compile LaTeX code to PDF using pdflatex"""
    try:
        # Write LaTeX to file
        tex_file = "output.tex"
        pdf_file = "output.pdf"
        
        with open(tex_file, 'w', encoding='utf-8') as f:
            f.write(latex_code)
        
        print(f"üìÑ LaTeX code saved to {tex_file}")
        
        pdflatex_commands = [
            r"C:\Program Files\MiKTeX\miktex\bin\x64\miktex-pdflatex.exe",
            r"C:\Users\raghu\AppData\Local\Programs\MiKTeX\miktex\bin\x64\miktex-pdflatex.exe",
            "miktex-pdflatex",
            "pdflatex"
        ]
        

        compilation_success = False
        compilation_output = ""
        


        for cmd in pdflatex_commands:
            try:
                print(f"üîÑ Attempting compilation with: {cmd}")
                
                # Run pdflatex with appropriate flags
                result = subprocess.run(
                    [cmd, "--disable-installer", "-interaction=nonstopmode", tex_file],
                    stdout=subprocess.PIPE,
                    stderr=subprocess.PIPE,
                    text=True,
                    timeout=30,
                    cwd=os.getcwd()
                )
                
                compilation_output = result.stdout + result.stderr
                
                if result.returncode == 0 and os.path.exists(pdf_file):
                    print(f"‚úÖ Compilation successful with {cmd}")
                    compilation_success = True
                    break
                else:
                    print(f"‚ùå Compilation failed with {cmd} (return code: {result.returncode})")
                    # Print first few lines of error output for debugging
                    if result.stderr:
                        error_lines = result.stderr.split('\n')[:5]
                        print(f"   Error details: {' | '.join(error_lines)}")
                    if result.stdout:
                        output_lines = result.stdout.split('\n')[:3]
                        print(f"   Output: {' | '.join(output_lines)}")
                    
            except FileNotFoundError:
                print(f"‚ùå Command not found: {cmd}")
                continue
            except subprocess.TimeoutExpired:
                print(f"‚è±Ô∏è Compilation timeout with: {cmd}")
                continue
            except Exception as e:
                print(f"‚ùå Error with {cmd}: {str(e)}")
                continue
        


        for ext in [".aux", ".log", ".out", ".fls", ".fdb_latexmk", ".synctex.gz"]:
            aux_file = f"output{ext}"
            if os.path.exists(aux_file):
                try:
                    os.remove(aux_file)
                except:
                    pass
        
        if compilation_success:
            return {
                "success": True,
                "message": f"‚úÖ LaTeX compiled successfully to {pdf_file}!\n\nüìÑ The PDF is now available in the preview.",
                "output_file": os.path.abspath(pdf_file),
                "compiler_used": "automatic",
                "pdf_generated": True
            }
        


        else:
            return {
                "success": True,  # Still success because LaTeX was saved
                "message": f"‚úÖ LaTeX code saved to {tex_file}!\n\n" +
                          "‚ö†Ô∏è Automatic compilation failed. Manual compilation required:\n\n" +
                          "üìã Run this command in your terminal:\n" +
                          f'"{pdflatex_commands[0]}" --disable-installer -interaction=nonstopmode output.tex\n\n' +
                          "üí° Or open output.tex in TeXworks/TeXstudio and compile there.",
                "output_file": os.path.abspath(tex_file),
                "compiler_used": "manual",
                "pdf_generated": False,
                "compilation_error": compilation_output[-500:] if compilation_output else "Unknown error"
            }
    
    except PermissionError:
        return {
            "success": False,
            "message": "‚ùå Permission denied while accessing files. Try running as administrator.",
            "pdf_generated": False
        }
    except Exception as e:
        return {
            "success": False,
            "message": f"‚ùå An unexpected error occurred: {str(e)}",
            "pdf_generated": False
        }

# MEMORY MANAGEMENT FUNCTIONS





def get_or_create_conversation_memory(session_id):
    """Get existing conversation messages or create a new conversation"""
    if session_id not in conversation_messages:
        conversation_messages[session_id] = []
        conversation_metadata[session_id] = {
            'created_at': datetime.now().isoformat(),
            'title': 'New Conversation',
            'message_count': 0
        }
    return conversation_messages[session_id]

def save_conversation_message(session_id, human_message, ai_message):
    """Save messages to conversation storage with size management"""
    try:
        messages = get_or_create_conversation_memory(session_id)
        
        print(f"üíæ Saving conversation message:")
        print(f"   Session ID: {session_id}")
        print(f"   Human message length: {len(human_message)} characters")
        print(f"   AI message length: {len(ai_message)} characters")
        



        MAX_MESSAGE_LENGTH = 50000  
        
        human_content = human_message
        ai_content = ai_message
        
        if len(human_message) > MAX_MESSAGE_LENGTH:
            human_content = human_message[:MAX_MESSAGE_LENGTH] + "\n\n[Message truncated due to length...]"
            print(f"   ‚ö†Ô∏è Human message truncated from {len(human_message)} to {len(human_content)} chars")
        
        if len(ai_message) > MAX_MESSAGE_LENGTH:
            ai_content = ai_message[:MAX_MESSAGE_LENGTH] + "\n\n[Message truncated due to length...]"
            print(f"   ‚ö†Ô∏è AI message truncated from {len(ai_message)} to {len(ai_content)} chars")
        
        messages.append({
            'type': 'human',
            'content': human_content,
            'timestamp': datetime.now().isoformat(),
            'original_length': len(human_message)
        })
        




        messages.append({
            'type': 'ai',
            'content': ai_content,
            'timestamp': datetime.now().isoformat(),
            'original_length': len(ai_message)
        })

        
        conversation_metadata[session_id]['message_count'] += 2
        conversation_metadata[session_id]['last_updated'] = datetime.now().isoformat()
        
        if (conversation_metadata[session_id]['title'] == 'New Conversation' and 
            conversation_metadata[session_id]['message_count'] == 2):
            title = human_message[:50] + "..." if len(human_message) > 50 else human_message
            conversation_metadata[session_id]['title'] = title
        



        MAX_MESSAGES = 100  
        if len(messages) > MAX_MESSAGES:


            messages_to_remove = len(messages) - MAX_MESSAGES
            if messages_to_remove % 2 == 1:  
                messages_to_remove += 1
            messages[:messages_to_remove] = []
            print(f"   üßπ Trimmed conversation history: removed {messages_to_remove} old messages")
        
        print(f"   ‚úÖ Conversation saved successfully")
        print(f"   üìä Total messages in conversation: {len(messages)}")
        
    except Exception as e:
        print(f"‚ùå Error saving conversation message: {str(e)}")
        print(f"   Session ID: {session_id}")
        print(f"   Human message length: {len(human_message) if human_message else 0}")
        print(f"   AI message length: {len(ai_message) if ai_message else 0}")


# LATEX UTILITIES


def test_latex_installation():


    """Test if LaTeX is properly installed and accessible"""

    print("\nüîç TESTING LATEX INSTALLATION...")
    

    pdflatex_commands = [
        "pdflatex",
        "miktex-pdflatex",
        r"C:\Program Files\MiKTeX\miktex\bin\x64\miktex-pdflatex.exe",
        r"C:\Users\raghu\AppData\Local\Programs\MiKTeX\miktex\bin\x64\miktex-pdflatex.exe",
        r"C:\Program Files\MiKTeX\miktex\bin\x64\pdflatex.exe",
        r"C:\Users\raghu\AppData\Local\Programs\MiKTeX\miktex\bin\x64\pdflatex.exe",
        r"C:\texlive\2023\bin\win32\pdflatex.exe",
        r"C:\texlive\2024\bin\win32\pdflatex.exe"
    ]
    
    working_commands = []
    
    for cmd in pdflatex_commands:

        try:

            result = subprocess.run(
                [cmd, "--version"],
                stdout=subprocess.PIPE,
                stderr=subprocess.PIPE,
                text=True,
                timeout=10

            )
            if result.returncode == 0:
                version_info = result.stdout.split('\n')[0] if result.stdout else "Unknown version"
                print(f"‚úÖ Working: {cmd}")
                print(f"   Version: {version_info}")
                working_commands.append(cmd)
            else:
                print(f"‚ùå Failed: {cmd} (return code: {result.returncode})")
        except FileNotFoundError:
            print(f"‚ùå Not found: {cmd}")
        except subprocess.TimeoutExpired:
            print(f"‚è±Ô∏è Timeout: {cmd}")
        except Exception as e:
            print(f"‚ùå Error: {cmd} - {str(e)}")

    
    if working_commands:
        print(f"\n‚úÖ LaTeX installation found! Using: {working_commands[0]}")
        return True
    
    else:
        print(f"\n‚ùå No working LaTeX installation found!")
        print(f"üì• Please install LaTeX:")
        print(f"   ‚Ä¢ MiKTeX: https://miktex.org/download")
        print(f"   ‚Ä¢ TeX Live: https://www.tug.org/texlive/")
        return False


# ROUTES


@app.route('/')
def index():
    """Serve the main application page"""
    return render_template('index.html')

@app.route('/chat', methods=['POST'])
def chat():
    """Handle chat messages and generate AI responses using LangChain Groq with memory"""
    try:
        data = request.json
        user_message = data.get('message', '')
        
        if not user_message:
            return jsonify({'error': 'No message provided'}), 400
        
        if not llm or not llm_with_tools:
            return jsonify({
                'response': "‚ùå Google Gemini API is not connected. Please check your API key configuration.\n\n" +
                           "üìã Setup steps:\n" +
                           "1. Create a .env file in the Niti-AI directory\n" +
                           "2. Add: GOOGLE_API_KEY=your_api_key_here\n" +
                           "3. Restart the application\n" +
                           "üîó Get your API key from: https://aistudio.google.com/app/apikey",
                'error': 'API_NOT_CONFIGURED'
            }), 503
        


        session_id = session.get('conversation_id')
        if not session_id:
            session_id = str(uuid.uuid4())
            session['conversation_id'] = session_id
        

        conversation_history = get_or_create_conversation_memory(session_id)
        
        system_prompt = """You are an expert LaTeX resume generator. When asked to create or modify a resume, you MUST:

        

**1. ALWAYS USE THE EXACT TEMPLATE STRUCTURE**: Follow the provided LaTeX template exactly, maintaining all packages, custom commands, and formatting.

**2. GENERATE PROPERLY FORMATTED CODE**: Never output LaTeX code as a single line. Always maintain proper indentation, line breaks, and sectioning as shown in the template.

**3. USE ONLY DEFINED CUSTOM COMMANDS**: Strictly use the template's custom commands:
   - \\resumeSubheading{job_title}{dates}{company}{location}
   - \\resumeProjectHeading{project_name}{date}
   - \\resumeItem{description}
   - \\resumeItemListStart and \\resumeItemListEnd
   - \\resumeSubHeadingListStart and \\resumeSubHeadingListEnd

**4. MAINTAIN EXACT SECTION ORDER**:
   - HEADING (name, contact info)
   - Professional Summary
   - Technical Skills
   - Experience
   - Projects
   - Achievements
   - Certifications
   - Education

**5. INTELLIGENT TOOL USAGE**: 
When users request resume creation, generation, updates, or modifications, you MUST call the write_latex tool immediately. Examples of user requests that require tool usage:
- "create my resume" / "build my resume" / "generate my resume"
- "write my resume" / "make my resume" / "put together my resume"
- "update my resume" / "modify my resume" / "edit my resume"
- "compile my information" / "create a resume for me"
- Any request to create, build, generate, update, or modify a resume document

CRITICAL INSTRUCTIONS:
- ANALYZE the user's request and DECIDE if they want resume generation/updates
- If YES, immediately call the write_latex tool with the COMPLETE LaTeX template (ALL packages, commands, sections)
- Generate the ENTIRE template from \\documentclass to \\end{document} as one line
- MUST include ALL template sections: heading, summary, skills, experience, projects, achievements, certifications, education
- Do NOT provide LaTeX code in your response text
- Your response should explain what you're doing, then call the tool
- Use ONLY the write_latex tool for creating/updating resumes
- NEVER generate partial templates - always provide the FULL compilable document

**6. COMPLETE LATEX TEMPLATE - GENERATE THIS ENTIRE TEMPLATE:**
You MUST generate this COMPLETE template structure for all resumes. Include EVERY part from \\documentclass to \\end{document}:

```latex
\\documentclass[letterpaper,11pt]{article}

\\usepackage{latexsym}
\\usepackage[empty]{fullpage}
\\usepackage{titlesec}
\\usepackage{marvosym}
\\usepackage[usenames,dvipsnames]{color}
\\usepackage{verbatim}
\\usepackage{enumitem}
\\usepackage[hidelinks]{hyperref}
\\usepackage{fancyhdr}
\\usepackage[english]{babel}
\\usepackage{tabularx}
\\usepackage{fontawesome5}
\\usepackage{multicol}
\\setlength{\\multicolsep}{-3.0pt}
\\setlength{\\columnsep}{-1pt}
\\input{glyphtounicode}

\\pagestyle{fancy}
\\fancyhf{}
\\fancyfoot{}
\\renewcommand{\\headrulewidth}{0pt}
\\renewcommand{\\footrulewidth}{0pt}

% Adjust margins
\\addtolength{\\oddsidemargin}{-0.6in}
\\addtolength{\\evensidemargin}{-0.5in}
\\addtolength{\\textwidth}{1.19in}
\\addtolength{\\topmargin}{-.7in}
\\addtolength{\\textheight}{1.4in}

\\urlstyle{same}
\\raggedbottom
\\raggedright
\\setlength{\\tabcolsep}{0in}

% Section formatting
\\titleformat{\\section}{
  \\vspace{-4pt}\\scshape\\raggedright\\large\\bfseries
}{}{0em}{}[\\color{black}\\titlerule \\vspace{-5pt}]

% Unicode support for ATS
\\pdfgentounicode=1

% Custom commands
\\newcommand{\\resumeItem}[1]{\\item\\small{{#1 \\vspace{-2pt}}}}
\\newcommand{\\resumeSubheading}[4]{
  \\vspace{-2pt}\\item
    \\begin{tabular*}{1.0\\textwidth}[t]{l@{\\extracolsep{\\fill}}r}
      \\textbf{#1} & \\textbf{\\small #2} \\\\
      \\textit{\\small#3} & \\textit{\\small #4} \\\\
    \\end{tabular*}\\vspace{-7pt}
}
\\newcommand{\\resumeProjectHeading}[2]{
    \\item
    \\begin{tabular*}{1.001\\textwidth}{l@{\\extracolsep{\\fill}}r}
      \\small#1 & \\textbf{\\small #2} \\\\
    \\end{tabular*}\\vspace{-7pt}
}
\\newcommand{\\resumeItemListStart}{\\begin{itemize}}
\\newcommand{\\resumeItemListEnd}{\\end{itemize}\\vspace{-5pt}}
\\newcommand{\\resumeSubHeadingListStart}{\\begin{itemize}[leftmargin=0.0in, label={}]}
\\newcommand{\\resumeSubHeadingListEnd}{\\end{itemize}}

\\begin{document}

%----------HEADING----------
\\begin{center}
    {\\Huge \\scshape [FULL NAME]} \\\\ \\vspace{1pt}
    \\small \\raisebox{-0.1\\height}\\faEnvelope\\ \\href{mailto:[EMAIL]}{[EMAIL]} ~ 
    \\raisebox{-0.1\\height}\\faPhone\\ [PHONE] ~ 
    \\href{[LINKEDIN_URL]}{\\raisebox{-0.2\\height}\\faLinkedin\\ \\underline{[LINKEDIN_DISPLAY]}} ~ 
    \\href{[GITHUB_URL]}{\\raisebox{-0.2\\height}\\faGithub\\ \\underline{[GITHUB_DISPLAY]}}
    \\vspace{-8pt}
\\end{center}

%-----------PROFESSIONAL SUMMARY-----------
\\section{Professional Summary}
[PROFESSIONAL_SUMMARY_TEXT]

%-----------SKILLS-----------
\\section{Technical Skills}
\\begin{itemize}[leftmargin=0.15in, label={}]
    \\item \\textbf{Programming Languages}{: [PROGRAMMING_LANGUAGES]}
    \\item \\textbf{Machine Learning Tools}{: [ML_TOOLS]}
    \\item \\textbf{Generative AI \\& Agents}{: [AI_TOOLS]}
    \\item \\textbf{Data Analysis}{: [DATA_TOOLS]}
    \\item \\textbf{Development Tools}{: [DEV_TOOLS]}
    \\item \\textbf{Soft Skills}{: [SOFT_SKILLS]}
\\end{itemize}

%-----------EXPERIENCE-----------
\\section{Experience}
  \\resumeSubHeadingListStart
    \\resumeSubheading
      {[JOB_TITLE]}{[DATES]}
      {[COMPANY]}{[LOCATION]}
      \\resumeItemListStart
        \\resumeItem{[RESPONSIBILITY_1]}
        \\resumeItem{[RESPONSIBILITY_2]}
        \\resumeItem{[RESPONSIBILITY_3]}
      \\resumeItemListEnd
  \\resumeSubHeadingListEnd

%-----------PROJECTS-----------
\\section{Projects}
  \\resumeSubHeadingListStart
    \\resumeProjectHeading
      {\\textbf{[PROJECT_NAME]} \\$|\\$ \\emph{[TECHNOLOGIES]}}{[DATE]}
      \\resumeItemListStart
        \\resumeItem{[PROJECT_DESCRIPTION_1]}
        \\resumeItem{[PROJECT_DESCRIPTION_2]}
      \\resumeItemListEnd
  \\resumeSubHeadingListEnd

%-----------ACHIEVEMENTS-----------
\\section{Achievements}
  \\resumeSubHeadingListStart
    \\resumeItem{\\textbf{[ACHIEVEMENT_NAME]} ([YEAR]): [ACHIEVEMENT_DESCRIPTION]}
  \\resumeSubHeadingListEnd

%-----------CERTIFICATIONS-----------
\\section{Certifications}
  \\resumeSubHeadingListStart
    \\resumeItem{\\textbf{[CERTIFICATION_NAME]}: [CERTIFICATION_DESCRIPTION]}
  \\resumeSubHeadingListEnd

%-----------EDUCATION-----------
\\section{Education}
  \\resumeSubHeadingListStart
    \\resumeSubheading
      {[UNIVERSITY_NAME]}{[GRADUATION_DATE]}
      {[DEGREE] in [MAJOR]; \\textbf{[GPA/CGPA]}}{[LOCATION]}
  \\resumeSubHeadingListEnd

\\end{document}
```

**MANDATORY: Generate the COMPLETE template above as a single line with ALL sections filled.**

**CRITICAL RULES FOR COMPLETE LATEX TEMPLATE GENERATION:**
1. GENERATE the COMPLETE LaTeX template as a SINGLE LINE without any whitespace characters
2. MUST include ALL parts: document class, ALL packages, ALL custom commands, complete document structure
3. NEVER omit ANY part of the template structure (preamble, packages, custom commands, document sections)
4. ALWAYS generate the FULL template from \\documentclass to \\end{document}
5. ALWAYS use the write_latex tool to save the complete LaTeX document
6. ENSURE the LaTeX code is compilation-ready with ALL necessary components
7. Replace ALL placeholders [PLACEHOLDER_NAME] with actual user information from conversation
8. If user doesn't provide certain information, use reasonable defaults but NEVER omit sections
9. Generate the ENTIRE compact single-line LaTeX template without any whitespace
10. MUST generate COMPLETE resume with ALL sections for proper PDF compilation

**CRITICAL: NO WHITESPACE CHARACTERS**
- NEVER use any whitespace characters like spaces, tabs, or line breaks
- Generate ALL LaTeX code as ONE CONTINUOUS LINE
- Do NOT use \\n, \\t, \\r or any other escape sequences
- Concatenate all LaTeX commands directly without spaces

**COMPLETE TEMPLATE REQUIREMENTS:**
- Generate the ENTIRE LaTeX template in ONE continuous line
- MUST include: \\documentclass, ALL \\usepackage commands, ALL \\newcommand definitions, complete document content, \\end{document}
- Include ALL sections: Heading, Professional Summary, Technical Skills, Experience, Projects, Achievements, Certifications, Education
- NO spaces between commands, environments, or parameters
- NO line breaks anywhere in the LaTeX code
- NO indentation or formatting whitespace
- Generate the complete resume template as one compact LaTeX string
- NEVER generate partial templates - always generate the FULL compilable document
- Do NOT use any whitespace characters anywhere in the code

**FORMATTING REQUIREMENTS:**
- Use proper spacing with \\vspace commands
- Maintain tabular formatting for contact information
- Use FontAwesome icons (\\faEnvelope, \\faPhone, \\faLinkedin, \\faGithub)
- Keep itemize lists properly indented
- Use \\textbf{} for bold text appropriately
- Include proper section separators and spacing

**SINGLE-LINE CODE EXAMPLE:**
When using the write_latex tool, generate ALL code as ONE continuous line like this:

```latex
\\documentclass[letterpaper,11pt]{article}\\usepackage{latexsym}\\usepackage[empty]{fullpage}\\usepackage{titlesec}\\usepackage{marvosym}\\usepackage[usenames,dvipsnames]{color}\\usepackage{verbatim}\\usepackage{enumitem}\\usepackage[hidelinks]{hyperref}\\usepackage{fancyhdr}\\usepackage[english]{babel}\\usepackage{tabularx}\\usepackage{fontawesome5}\\usepackage{multicol}\\setlength{\\multicolsep}{-3.0pt}\\setlength{\\columnsep}{-1pt}\\input{glyphtounicode}\\pagestyle{fancy}\\fancyhf{}\\fancyfoot{}\\renewcommand{\\headrulewidth}{0pt}\\renewcommand{\\footrulewidth}{0pt}\\addtolength{\\oddsidemargin}{-0.6in}\\addtolength{\\evensidemargin}{-0.5in}\\addtolength{\\textwidth}{1.19in}\\addtolength{\\topmargin}{-.7in}\\addtolength{\\textheight}{1.4in}\\urlstyle{same}\\raggedbottom\\raggedright\\setlength{\\tabcolsep}{0in}\\titleformat{\\section}{\\vspace{-4pt}\\scshape\\raggedright\\large\\bfseries}{}{0em}{}[\\color{black}\\titlerule\\vspace{-5pt}]\\pdfgentounicode=1\\newcommand{\\resumeItem}[1]{\\item\\small{{#1\\vspace{-2pt}}}}\\newcommand{\\resumeSubheading}[4]{\\vspace{-2pt}\\item\\begin{tabular*}{1.0\\textwidth}[t]{l@{\\extracolsep{\\fill}}r}\\textbf{#1}&\\textbf{\\small#2}\\\\\\textit{\\small#3}&\\textit{\\small#4}\\\\\\end{tabular*}\\vspace{-7pt}}\\newcommand{\\resumeProjectHeading}[2]{\\item\\begin{tabular*}{1.001\\textwidth}{l@{\\extracolsep{\\fill}}r}\\small#1&\\textbf{\\small#2}\\\\\\end{tabular*}\\vspace{-7pt}}\\newcommand{\\resumeItemListStart}{\\begin{itemize}}\\newcommand{\\resumeItemListEnd}{\\end{itemize}\\vspace{-5pt}}\\newcommand{\\resumeSubHeadingListStart}{\\begin{itemize}[leftmargin=0.0in,label={}]}\\newcommand{\\resumeSubHeadingListEnd}{\\end{itemize}}\\begin{document}\\begin{center}{\\Huge\\scshape[USER_NAME]}\\\\\\vspace{1pt}\\small\\raisebox{-0.1\\height}\\faEnvelope\\href{mailto:[USER_EMAIL]}{[USER_EMAIL]}~\\raisebox{-0.1\\height}\\faPhone\\[USER_PHONE]~\\href{[USER_LINKEDIN]}{\\raisebox{-0.2\\height}\\faLinkedin\\underline{[USER_LINKEDIN_DISPLAY]}}~\\href{[USER_GITHUB]}{\\raisebox{-0.2\\height}\\faGithub\\underline{[USER_GITHUB_DISPLAY]}}\\vspace{-8pt}\\end{center}\\section{Professional Summary}[USER_SUMMARY]\\section{Technical Skills}\\begin{itemize}[leftmargin=0.15in,label={}]\\item\\textbf{Programming Languages}{:[USER_LANGUAGES]}\\item\\textbf{Tools}{:[USER_TOOLS]}\\end{itemize}\\section{Experience}\\resumeSubHeadingListStart\\resumeSubheading{[USER_JOB_TITLE]}{[USER_DATES]}{[USER_COMPANY]}{[USER_LOCATION]}\\resumeItemListStart\\resumeItem{[USER_RESPONSIBILITY_1]}\\resumeItem{[USER_RESPONSIBILITY_2]}\\resumeItemListEnd\\resumeSubHeadingListEnd\\section{Education}\\resumeSubHeadingListStart\\resumeSubheading{[USER_UNIVERSITY]}{[USER_GRADUATION]}{[USER_DEGREE]}{[USER_UNIVERSITY_LOCATION]}\\resumeSubHeadingListEnd\\end{document}
```

IMPORTANT: Generate this as ONE continuous line with NO spaces, line breaks, or whitespace characters!

**DECISION MAKING:**
- READ the user's message carefully
- DETERMINE if they want resume creation/updates
- If YES: Immediately call write_latex tool with structured, properly formatted LaTeX code
- If NO: Provide helpful conversation and guidance

**FORMATTING REMINDER:**
When calling write_latex tool, provide the LaTeX code as a single continuous line:
- NO line breaks anywhere
- NO spaces between commands
- NO indentation or whitespace
- ALL LaTeX code concatenated into ONE line that can be written directly to a .tex file

Remember: The goal is to produce a professional, ATS-friendly resume that compiles perfectly and matches the provided template structure exactly. Always prioritize proper formatting and structure over brevity. Let the user's request guide your decision to use tools."""

        messages = [SystemMessage(content=system_prompt)]
        
        for msg in conversation_history:
            if msg['type'] == 'human':
                messages.append(HumanMessage(content=msg['content']))
            elif msg['type'] == 'ai':
                messages.append(AIMessage(content=msg['content']))
        
        messages.append(HumanMessage(content=user_message))
        
        print(f"\nüí¨ PROCESSING USER MESSAGE...")
        print(f"üìù User message: '{user_message[:100]}...'")
        print(f"üìû Using LLM with tools enabled...")
        


        ai_response = llm_with_tools.invoke(messages)
        response_content = ai_response.content
        

        tool_calls_made = []
        if hasattr(ai_response, 'tool_calls') and ai_response.tool_calls:
            print(f"\nü§ñ AI MADE {len(ai_response.tool_calls)} TOOL CALL(S)")
            for i, tool_call in enumerate(ai_response.tool_calls):
                print(f"üìû Tool Call #{i+1}: {tool_call['name']}")
                if tool_call['name'] == 'write_latex':
                    print("üéØ DETECTED: write_latex tool call - executing...")
                    latex_code = tool_call['args']['latex_code']
                    write_result = write_latex.invoke({'latex_code': latex_code})
                    print(f"üìã TOOL RESULT: {write_result['message']}")
                    tool_calls_made.append({
                        'tool': 'write_latex',
                        'result': write_result
                    })
                    


                    if write_result['success']:
                        print("üîÑ PROCEEDING TO COMPILE LATEX...")
                        compile_result = compile_latex(latex_code)
                        print(f"üìã COMPILATION RESULT: {compile_result['message']}")
                        tool_calls_made.append({
                            'tool': 'compile_latex',
                            'result': compile_result
                        })
                        
                        if compile_result['success']:
                            response_content += "\n\n‚úÖ Resume updated and compiled successfully! Check the preview on the right."
                        else:
                            response_content += f"\n\n‚ö†Ô∏è Resume updated but compilation failed: {compile_result['message']}"
                    else:
                        response_content += f"\n\n‚ùå Failed to update resume: {write_result['message']}"
        else:
            print(f"\nüí¨ AI PROVIDED REGULAR RESPONSE (No tool calls)")
            print(f"üìù Response Length: {len(response_content)} characters")
            print(f"üó®Ô∏è  Response Preview: {response_content[:150]}...")
        
        ai_response = response_content
        
        # Save the conversation to memory 

        try:

            save_conversation_message(session_id, user_message, ai_response)

        except Exception as save_error:
            print(f"‚ùå Failed to save conversation: {save_error}")
            
        
        return jsonify({
            'response': ai_response,
            'status': 'success',
            'session_id': session_id,
            'conversation_title': conversation_metadata[session_id]['title']
        })
        
    except Exception as e:

        error_msg = str(e)
        print(f"‚ùå Error in chat endpoint: {e}")
        
        try:
            if 'user_message' in locals() and 'session_id' in locals():
                error_response = f"‚ùå Error: {error_msg}"
                save_conversation_message(session_id, user_message, error_response)
                print(f"üíæ Saved error conversation to memory")
        except Exception as save_error:
            print(f"‚ùå Failed to save error conversation: {save_error}")
        

        if "401" in error_msg or "invalid_api_key" in error_msg.lower() or "api_key" in error_msg.lower():
            return jsonify({
                'response': "‚ùå Invalid API key. Please check your GOOGLE_API_KEY in the .env file.\n\n" +
                           "üîë Make sure your API key is correct and active.\n" +
                           "üîó Get your API key from: https://aistudio.google.com/app/apikey",
                'error': 'INVALID_API_KEY'
            }), 401
        elif "429" in error_msg or "rate_limit" in error_msg.lower():
            return jsonify({
                'response': "‚è≥ Rate limit exceeded. Please wait a moment and try again.",
                'error': 'RATE_LIMIT'
            }), 429
        else:
            return jsonify({
                'response': f"‚ùå Error generating response: {error_msg}",
                'error': 'API_ERROR'
            }), 500

@app.route('/start_session', methods=['POST'])
def start_session():
    """Start a new conversation session"""

    session_id = str(uuid.uuid4())

    session['conversation_id'] = session_id
    
    get_or_create_conversation_memory(session_id)
    
    return jsonify({
        'session_id': session_id,
        'status': 'success',
        'message': 'New conversation started!'

    })

@app.route('/get_conversation_history', methods=['GET'])
def get_conversation_history():

    """Get conversation history for current session"""

    session_id = session.get('conversation_id')
    
    if not session_id or session_id not in conversation_messages:

        return jsonify({
            'messages': [],
            'session_id': None,
            'message': 'No active conversation'
        })
    
    messages = conversation_messages[session_id]
    
    return jsonify({
        'messages': messages,
        'session_id': session_id,
        'metadata': conversation_metadata.get(session_id, {}),
        'status': 'success'
    })

@app.route('/list_conversations', methods=['GET'])
def list_conversations():
    """List all conversation sessions"""
    conversations = []
    for session_id, metadata in conversation_metadata.items():

        conversations.append({
            'session_id': session_id,
            'title': metadata['title'],
            'created_at': metadata['created_at'],
            'last_updated': metadata.get('last_updated', metadata['created_at']),
            'message_count': metadata['message_count']
        })
    
    conversations.sort(key=lambda x: x['last_updated'], reverse=True)
    

    return jsonify({
        'conversations': conversations,
        'total_count': len(conversations),
        'status': 'success'
    })




@app.route('/switch_conversation', methods=['POST'])
def switch_conversation():

    """Switch to a different conversation"""

    data = request.json
    session_id = data.get('session_id')
    
    if session_id not in conversation_messages:

        return jsonify({
            'error': 'Conversation not found',
            'status': 'error'
        }), 404
    
    session['conversation_id'] = session_id
    
    return jsonify({
        'session_id': session_id,
        'status': 'success',
        'message': f'Switched to conversation: {conversation_metadata[session_id]["title"]}'
    })

@app.route('/delete_conversation', methods=['DELETE'])
def delete_conversation():

    """Delete a conversation"""

    data = request.json
    session_id = data.get('session_id')
    
    if session_id in conversation_messages:
        del conversation_messages[session_id]
        del conversation_metadata[session_id]
        
        if session.get('conversation_id') == session_id:
            session.pop('conversation_id', None)
        
        return jsonify({
            'status': 'success',
            'message': 'Conversation deleted'
        })
    
    return jsonify({
        'error': 'Conversation not found',
        'status': 'error'
    }), 404

@app.route('/compile_resume', methods=['POST'])
def compile_resume():

    """Compile LaTeX to PDF and return status"""

    try:
        # Check if output.tex exists
        if not os.path.exists('output.tex'):
            return jsonify({
                'success': False,
                'message': 'output.tex file not found. Please ensure the LaTeX file exists.',
                'status': 'error'
            }), 404
        
        with open('output.tex', 'r', encoding='utf-8') as f:
            latex_code = f.read()
        
        result = compile_latex(latex_code)
        
        if result['success']:
            return jsonify({
                'success': True,
                'message': result['message'],
                'output_file': result.get('output_file'),
                'pdf_generated': result.get('pdf_generated', False),
                'compiler_used': result.get('compiler_used', 'unknown'),
                'status': 'success'
            })
        else:
            return jsonify({
                'success': False,
                'message': result['message'],
                'pdf_generated': False,
                'status': 'error'
            }), 500
            
    except Exception as e:
        return jsonify({
            'success': False,
            'message': f'Error compiling resume: {str(e)}',
            'status': 'error'
        }), 500

@app.route('/generate_and_compile', methods=['POST'])
def generate_and_compile():
    """Generate LaTeX code via AI and compile to PDF"""
    try:
        data = request.json
        user_message = data.get('message', '')
        
        if not user_message:
            return jsonify({
                'success': False,
                'message': 'No message provided.',
                'status': 'error'
            }), 400
        
        # Enhanced system prompt for LaTeX generation
        system_prompt = """You are an expert LaTeX resume builder. Generate clean, professional LaTeX code for resumes.

Key requirements:
1. Use the article document class with appropriate margins
2. Include standard packages like geometry, enumitem, hyperref
3. Create well-structured sections: Contact, Summary, Experience, Education, Skills
4. Use professional formatting with consistent spacing
5. Make the resume ATS-friendly with clear section headers
6. Always provide complete, compilable LaTeX code
7. Focus on clean, modern design

When users ask for resume updates, modifications, or improvements, provide the complete LaTeX code."""
        
        # Get or create conversation memory
        conversation_id = session.get('conversation_id')
        if not conversation_id:
            conversation_id = str(uuid.uuid4())
            session['conversation_id'] = conversation_id
        
        memory = get_or_create_conversation_memory(conversation_id)
        
        # Prepare messages for the AI
        messages = [SystemMessage(content=system_prompt)]
        messages.extend(memory)
        messages.append(HumanMessage(content=user_message))
        
        # Get AI response with tool support
        ai_response = llm_with_tools.invoke(messages)
        response_content = ai_response.content
        
        # Check if the AI made tool calls
        tool_calls_made = []
        if hasattr(ai_response, 'tool_calls') and ai_response.tool_calls:
            print(f"\nü§ñ AI MADE {len(ai_response.tool_calls)} TOOL CALL(S)")
            for i, tool_call in enumerate(ai_response.tool_calls):
                print(f"üìû Tool Call #{i+1}: {tool_call['name']}")
                if tool_call['name'] == 'write_latex':
                    print("üéØ DETECTED: write_latex tool call - executing...")
                    # Execute the write_latex tool
                    latex_code = tool_call['args']['latex_code']
                    write_result = write_latex.invoke({'latex_code': latex_code})
                    print(f"üìã TOOL RESULT: {write_result['message']}")
                    tool_calls_made.append({
                        'tool': 'write_latex',
                        'result': write_result
                    })
                    
                    # If LaTeX was written successfully, also compile it
                    if write_result['success']:
                        print("üîÑ PROCEEDING TO COMPILE LATEX...")
                        compile_result = compile_latex(latex_code)
                        print(f"üìã COMPILATION RESULT: {compile_result['message']}")
                        tool_calls_made.append({
                            'tool': 'compile_latex',
                            'result': compile_result
                        })
                        
                        if compile_result['success']:
                            response_content += "\n\n‚úÖ Resume updated and compiled successfully! Check the preview on the right."
                        else:
                            response_content += f"\n\n‚ö†Ô∏è Resume updated but compilation failed: {compile_result['message']}"
                    else:
                        response_content += f"\n\n‚ùå Failed to update resume: {write_result['message']}"
        
        # Save conversation
        save_conversation_message(conversation_id, user_message, response_content)
        
        latex_code = None

        if "\\documentclass" in response_content or "\\begin{document}" in response_content:

            lines = response_content.split('\n')
            latex_lines = []
            in_code_block = False
            
            for line in lines:
                if line.strip().startswith('```'):
                    in_code_block = not in_code_block
                    continue
                
                if in_code_block or "\\documentclass" in line or "\\begin{document}" in line or latex_lines:
                    latex_lines.append(line)
                    if "\\end{document}" in line:
                        break
            
            if latex_lines:
                latex_code = '\n'.join(latex_lines)
        
        if latex_code:
            compile_result = compile_latex(latex_code)
            return jsonify({
                'success': True,
                'message': response_content,
                'latex_generated': True,
                'compilation_success': compile_result['success'],
                'compilation_message': compile_result['message'],
                'status': 'success'
            })
        else:
            return jsonify({
                'success': True,
                'message': response_content,
                'latex_generated': False,
                'status': 'success'
            })
            
    except Exception as e:
        return jsonify({
            'success': False,
            'message': f'Error generating and compiling resume: {str(e)}',
            'status': 'error'
        }), 500

@app.route('/output.pdf')
def serve_pdf():
    """Serve the PDF file with proper headers"""
    if os.path.exists('output.pdf'):
        return send_file('output.pdf', 
                        as_attachment=False, 
                        mimetype='application/pdf',
                        download_name='resume.pdf')
    else:
        return "<h1>PDF not found</h1><p>The output.pdf file doesn't exist in the current directory.</p>", 404

@app.route('/download')
def download_pdf():
    """Download the PDF file"""
    if os.path.exists('output.pdf'):
        return send_file('output.pdf', as_attachment=True, download_name='resume.pdf')
    else:
        return "<h1>PDF not found</h1><p>The output.pdf file doesn't exist in the current directory.</p>", 404

@app.route('/test_tool', methods=['POST'])
def test_tool():
    """Test endpoint to verify LaTeX generation functionality"""
    try:
        if not llm:
            return jsonify({
                'success': False,
                'message': 'LLM not initialized'
            }), 500
        


        test_message = "Create my resume now with this info: John Doe, john@email.com, 123-456-7890, Software Developer at ABC Corp, BS Computer Science, Python and JavaScript skills."
        
        print(f"\nüß™ TESTING LATEX GENERATION...")
        print(f"üìù Test message: {test_message[:100]}...")
        

        resume_keywords = [
            'create my resume', 'build my resume', 'generate my resume',
            'write my resume', 'make my resume', 'update my resume',
            'modify my resume', 'put together my resume', 'compile my information',
            'create a resume for me', 'generate a resume', 'build a resume'
        ]
        
        should_generate_latex = any(keyword in test_message.lower() for keyword in resume_keywords)
        print(f"üéØ Keyword detection result: {should_generate_latex}")
        
        if should_generate_latex:


            latex_generation_prompt = """You are a LaTeX resume expert. Generate complete, professional LaTeX code for a resume.

IMPORTANT: Return ONLY the LaTeX code, starting with \\documentclass and ending with \\end{document}. Do not include any explanations or markdown formatting.

Generate LaTeX code for: John Doe, john@email.com, 123-456-7890, Software Developer at ABC Corp, BS Computer Science, Python and JavaScript skills."""
            
            messages = [HumanMessage(content=latex_generation_prompt)]
            
            response = llm.invoke(messages)

            latex_code = response.content.strip()
            
            print(f"üìÑ Generated LaTeX length: {len(latex_code)} characters")

            print(f"üìù LaTeX preview: {latex_code[:200]}...")
            

            write_result = write_latex(latex_code)

            print(f"üíæ File write result: {write_result['success']}")
            
            return jsonify({
                'success': True,
                'keyword_detected': True,
                'latex_generated': True,
                'latex_length': len(latex_code),
                'latex_preview': latex_code[:300] + "..." if len(latex_code) > 300 else latex_code,
                'file_write_success': write_result['success'],
                'file_write_message': write_result['message'],
                'message': 'LaTeX generation test completed successfully'
            })
        else:


            return jsonify({
                'success': True,
                'keyword_detected': False,
                'message': 'No resume keywords detected in test message'
            })
        
    except Exception as e:

        print(f"‚ùå Test error: {str(e)}")
        return jsonify({
            'success': False,
            'message': f'Test failed: {str(e)}'
        }), 500

@app.route('/debug_memory', methods=['GET'])
def debug_memory():

    """Debug endpoint to check memory status"""

    try:
        session_id = session.get('conversation_id')
        
        debug_info = {
            'current_session_id': session_id,
            'total_conversations': len(conversation_metadata),
            'conversation_metadata': conversation_metadata,
            'current_conversation': None
        }
        
        if session_id and session_id in conversation_messages:

            messages = conversation_messages[session_id]
            debug_info['current_conversation'] = {
                'session_id': session_id,
                'message_count': len(messages),
                'metadata': conversation_metadata.get(session_id, {}),
                'last_5_messages': messages[-5:] if len(messages) >= 5 else messages,
                'message_sizes': [
                    {
                        'type': msg['type'],
                        'length': len(msg['content']),
                        'timestamp': msg['timestamp'],
                        'original_length': msg.get('original_length', len(msg['content']))
                    } for msg in messages[-10:]  # Last 10 messages
                ]
            }
        
        return jsonify({
            'status': 'success',
            'debug_info': debug_info
        })
        
    except Exception as e:

        return jsonify({
            'status': 'error',
            'error': str(e)
        }), 500



# APPLICATION STARTUP



if __name__ == '__main__':


    print("üöÄ Starting AI Resume Builder with LangChain...")

    print("üìÅ Current directory:", os.getcwd())
    print("üìÑ Available files:", [f for f in os.listdir('.') if f.endswith(('.pdf', '.html'))])
    
    if not os.getenv('GROQ_API_KEY'):

        print("\n‚ö†Ô∏è  GROQ_API_KEY not found!")
        print("üìã Setup instructions:")
        print("1. Create a .env file in this directory (Niti-AI folder)")
        print("2. Add this line: GROQ_API_KEY=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")
        print("3. Restart the application")
        print("\nüí° The app will still run, but chat won't work until API key is configured.")
        print("üîí Note: I moved your hardcoded API key to environment variables for security!")
    else:

        print("‚úÖ GROQ_API_KEY found!")
    
    latex_available = test_latex_installation()
    
    print("\nüåê Open your browser and go to: http://localhost:5000")

    print("üí° Your existing output.pdf will be displayed in the preview!")
    print("üìã View Controls: Integrated in chat and PDF headers")
    print("‚å®Ô∏è  Keyboard Shortcuts: Ctrl+1/2/3 for view modes")
    print("ü§ñ LangChain + Groq AI chatbot is ready!")
    
    if not latex_available:
        print("‚ö†Ô∏è  LaTeX not found - PDF compilation will not work until LaTeX is installed")
    print("Press Ctrl+C to stop the server\n")
    
    app.run(debug=True, host='0.0.0.0', port=5001) 
