{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "02d130a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intro to Deep Learning!Kaggle!March 12, 2024\n"
     ]
    }
   ],
   "source": [
    "from together import Together\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "import base64\n",
    "import json\n",
    "\n",
    "imagePath= r\"C:\\Users\\raghu\\OneDrive\\Desktop\\Latex MCP\\Raghunandhan G - Intro to Deep Learning.png\"\n",
    "\n",
    "def encode_image(image_path):\n",
    "        with open(image_path, \"rb\") as image_file:\n",
    "            return base64.b64encode(image_file.read()).decode('utf-8')\n",
    "        \n",
    "base64_image = encode_image(imagePath)\n",
    "\n",
    "\n",
    "client = Together()\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=\"meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8\",\n",
    "    messages=[\n",
    "      {\n",
    "        \"role\": \"system\",\n",
    "        \"content\": \"You are an helpful data extraction assitant who supports data extraction from both images and text. The user will provide images of certifications that he/she had completed. you need to extract the name of the certification, certificate provider and data of completion if availabe \\n\\ni need you to only output the data that is required  dont not generate anyother text \\ni need only the data \\n\\nhere is the format of the data to be extracted \\n\\n\\nname_of_certification<must>certification_provider_name<must>, date<optional>\"\n",
    "      },\n",
    "      {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": [\n",
    "          {\n",
    "            \"type\": \"text\",\n",
    "            \"text\": \"give me the data content in this image \"\n",
    "          },\n",
    "          {\n",
    "            \"type\": \"image_url\",\n",
    "            \"image_url\": {\n",
    "              \"url\": f\"data:image/jpeg;base64,{base64_image}\"\n",
    "            }\n",
    "          }\n",
    "        ]\n",
    "      },\n",
    "      {\n",
    "        \"role\": \"assistant\",\n",
    "        \"content\": \"Intro to Deep Learning!Kaggle, March 12, 2024\"\n",
    "      }\n",
    "    ],\n",
    "\n",
    ")\n",
    "print(response.choices[0].message.content)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "46398b34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here are the extracted details from the image:\n",
      "\n",
      "*   **Certification Name:** Intro to Deep Learning\n",
      "*   **Provider:** Kaggle\n",
      "*   **Completion Date:** March 12, 2024\n"
     ]
    }
   ],
   "source": [
    "import base64\n",
    "import os\n",
    "from google import genai\n",
    "from google.genai import types\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "def generate_from_image(image_path: str):\n",
    "    client = genai.Client(api_key=os.environ[\"GEMINI_API_KEY\"])\n",
    "\n",
    "    # Read and prepare image bytes\n",
    "    with open(image_path, \"rb\") as imgf:\n",
    "        img_bytes = imgf.read()\n",
    "\n",
    "    # Build prompt: image + instruction text\n",
    "    contents = [\n",
    "        # User prompt\n",
    "        types.Content(\n",
    "            role=\"user\",\n",
    "            parts=[\n",
    "                # Inline image part\n",
    "                types.Part.from_bytes(\n",
    "                    data=img_bytes,\n",
    "                    mime_type=\"image/png\"\n",
    "                ),\n",
    "                # Prompt text part\n",
    "                types.Part.from_text(text=\"Extract the certification name, provider, and completion date.\")\n",
    "            ],\n",
    "        )\n",
    "    ]\n",
    "\n",
    "    response = client.models.generate_content(\n",
    "        model=\"gemini-2.0-flash\",\n",
    "        contents=contents,\n",
    "        config=types.GenerateContentConfig(\n",
    "            response_mime_type=\"text/plain\"\n",
    "        )\n",
    "    )\n",
    "\n",
    "    print(response.text)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    generate_from_image(r\"C:\\Users\\raghu\\OneDrive\\Desktop\\Latex MCP\\Raghunandhan G - Intro to Deep Learning.png\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4eaf791",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "niti",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
